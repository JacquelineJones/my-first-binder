{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca7d29-61d5-421e-b136-e96c89a33833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534ebd47-8711-4b64-9c83-5f337e7b802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a Make a function\n",
    "\n",
    "#b\n",
    "\n",
    "#c\n",
    "\n",
    "#d\n",
    "\n",
    "#e\n",
    "\n",
    "#f\n",
    "\n",
    "#g\n",
    "\n",
    "#h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a12cbb-a1bc-42c9-a8bd-321ed2a9310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f44c71-d921-4bbf-8465-b20ea3c3f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "#a What is a language learning model?\n",
    "#A LLM is a type of machine learning model that predicts the probability of word sequences and has the capacity to generate human language. \n",
    "#LLM takes the previous input and then calculates the probability distribution over words. \n",
    "#There is also a version called the Markov model that predicts future states by considering the current state rather than previous input.\n",
    "\n",
    "#b How do you run a llm locally?\n",
    "#You can run a language learning model locally using a tool like Ollama. Ollama can be downloaded through Homebrew on the terminal and then will allow you to talk to the langauge\n",
    "#model over HTTP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6babfa-7ad9-4fdb-9976-f5ffba553299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "Explain what the following vocab words mean in the context of typing mkdir project into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "\n",
    "Term\t               Meaning\n",
    "Shell\tA program that allows you to interact with the complete functionality of the system; \"shell\" around the OS\n",
    "Terminal emulator\tProvides the interface; sits between the user and an OS and the place the shell sits\n",
    "Process\tSomething running on your computer\n",
    "Signal\tThings we send to processes to tell them to do something\n",
    "Standard input\t(stdin) Default channel through which a program receives input data\n",
    "Standard output\t(stdout) Default channel through which a program sends its normal output data\n",
    "Command line argument\tThings we pass to a process when we start it\n",
    "The environment\tEverything that is visible while it is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488e840-5d12-4d35-8900-b8c01be1d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "\n",
    "#a\n",
    "\n",
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3089bc-f2b2-4175-9a1d-414b72f90cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6\n",
    "#Install docker \n",
    "\n",
    "#a Show the repsonse when you run docker\n",
    "\n",
    "#Access Rstudio through docker\n",
    "\n",
    "#How do you log in to the RStudio server?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
